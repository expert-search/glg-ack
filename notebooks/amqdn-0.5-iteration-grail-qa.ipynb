{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Iteration - Grail QA\n",
    "\n",
    "In our last analysis, we saw that there were specific terms that appeared frequently in our dataset. Let's build a model removing these stop words."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "stop_words = ['the', 'what', 'of', 'is', 'which', 'has', 'by', 'that', 'in', 'and', 'with', 'for', 'was', 'name', 'to', 'are', 'how', 'who', 'as', 'on', 'many', 'than', 'used', 'have', 'does', 'an']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.options.display.max_colwidth = 0"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "from src.data.utils import *\n",
    "\n",
    "train, dev = make_grail_qa()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "print(f'---Train Distribution---\\n{train.domains.value_counts()}')\n",
    "print(f'---Dev Distribution---\\n{dev.domains.value_counts()}')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "---Train Distribution---\n",
      "technology    4967\n",
      "healthcare    3250\n",
      "Name: domains, dtype: int64\n",
      "---Dev Distribution---\n",
      "technology    408\n",
      "healthcare    303\n",
      "Name: domains, dtype: int64\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(stop_words=stop_words)\n",
    "xt = tfidf.fit_transform(train.questions)\n",
    "xd = tfidf.transform(dev.questions)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "import numpy as np\n",
    "\n",
    "def transform_labels(labels):\n",
    "    labels[np.where(labels == 'healthcare')] = 0.\n",
    "    labels[np.where(labels == 'technology')] = 1.\n",
    "    return labels.astype(np.float64)\n",
    "\n",
    "yt = transform_labels(train.domains.values)\n",
    "yd = transform_labels(dev.domains.values)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(xt, yt)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "yh = clf.predict(xd)\n",
    "print(classification_report(yd, yh))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.98      0.99       303\n",
      "         1.0       0.99      1.00      0.99       408\n",
      "\n",
      "    accuracy                           0.99       711\n",
      "   macro avg       0.99      0.99      0.99       711\n",
      "weighted avg       0.99      0.99      0.99       711\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print(confusion_matrix(yd, yh))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[298   5]\n",
      " [  0 408]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "# Find the misclassified examples\n",
    "mistakes_idxs = np.where(yd != yh)\n",
    "mistakes_lbls = yh[mistakes_idxs]\n",
    "mistakes = xd[mistakes_idxs].todense()\n",
    "\n",
    "for i, mistake in enumerate(mistakes):\n",
    "    print(tfidf.inverse_transform(mistake)[0].tolist(), mistakes_lbls[0])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['deracoxib'] 1.0\n",
      "['contraindications', 'temazepam'] 1.0\n",
      "['contraindications', 'deracoxib', 'number'] 1.0\n",
      "['contraindications', 'number', 'teriparatide'] 1.0\n",
      "['contraindications', 'teriparatide'] 1.0\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Even though the performance is slightly worse than before, we can trust our model a little bit more. Also, we can start to pinpoint those places where it fails because it cannot rely on stop words to guess. "
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.1",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.1 64-bit"
  },
  "interpreter": {
   "hash": "4cd7ab41f5fca4b9b44701077e38c5ffd31fe66a6cab21e0214b68d958d0e462"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}