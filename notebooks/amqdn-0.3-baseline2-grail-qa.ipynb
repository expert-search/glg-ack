{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Baseline 2 - Grail QA\n",
    "\n",
    "We have decided which subdomains of Grail QA will constitute our overall domains of `healthcare` and `technology`. Here, we'll perform another baseline with this data. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.options.display.max_colwidth = 0"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "from src.data.utils import *\n",
    "\n",
    "train = pd.DataFrame(get_domains_and_questions('train', 'grail_qa'))\n",
    "dev   = pd.DataFrame(get_domains_and_questions('dev',   'grail_qa'))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "domains = ['medicine', 'computer', 'spaceflight', 'biology', 'automotive', 'internet', 'engineering']\n",
    "train = set_domains(train, domains)\n",
    "dev   = set_domains(dev,   domains)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "healthcare_subdomains = ['medicine', 'biology']\n",
    "technology_subdomains = ['computer', 'spaceflight', 'automotive', 'internet', 'engineering']\n",
    "\n",
    "def set_label(df, label, subdomains):\n",
    "    df.domains.loc[df.domains.isin(subdomains)] = label\n",
    "    return df\n",
    "\n",
    "train = set_label(train, 'healthcare', healthcare_subdomains)\n",
    "train = set_label(train, 'technology', technology_subdomains)\n",
    "dev   = set_label(dev,   'healthcare', healthcare_subdomains)\n",
    "dev   = set_label(dev,   'technology', technology_subdomains)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "print(f'TRAIN DISTRIBUTION\\n{train.domains.value_counts()}')\n",
    "print(f'DEV DISTRIBUTION\\n{dev.domains.value_counts()}')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "TRAIN DISTRIBUTION\n",
      "technology    4967\n",
      "healthcare    3250\n",
      "Name: domains, dtype: int64\n",
      "DEV DISTRIBUTION\n",
      "technology    408\n",
      "healthcare    303\n",
      "Name: domains, dtype: int64\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "xt = tfidf.fit_transform(train.questions)\n",
    "xd = tfidf.transform(dev.questions)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "import numpy as np\n",
    "\n",
    "def transform_labels(labels):\n",
    "    labels[np.where(labels == 'healthcare')] = 0.\n",
    "    labels[np.where(labels == 'technology')] = 1.\n",
    "    return labels.astype(np.float64)\n",
    "\n",
    "yt = transform_labels(train.domains.values)\n",
    "yd = transform_labels(dev.domains.values)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(xt, yt)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(yd, clf.predict(xd)))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.99      1.00       303\n",
      "         1.0       0.99      1.00      1.00       408\n",
      "\n",
      "    accuracy                           1.00       711\n",
      "   macro avg       1.00      1.00      1.00       711\n",
      "weighted avg       1.00      1.00      1.00       711\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print(confusion_matrix(yd, clf.predict(xd)))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[300   3]\n",
      " [  0 408]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "# Find the misclassified examples\n",
    "mistakes = xd[np.where(yd != clf.predict(xd))].todense()\n",
    "\n",
    "for mistake in mistakes:\n",
    "    print(tfidf.inverse_transform(mistake)[0].tolist())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['been', 'by', 'contacted', 'has', 'heese', 'oliver', 'who']\n",
      "['contraindications', 'deracoxib', 'for', 'is', 'number', 'of', 'the', 'what']\n",
      "['contraindications', 'for', 'is', 'number', 'of', 'teriparatide', 'the', 'what']\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.1",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.1 64-bit"
  },
  "interpreter": {
   "hash": "4cd7ab41f5fca4b9b44701077e38c5ffd31fe66a6cab21e0214b68d958d0e462"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}